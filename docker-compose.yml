version: '3.8'
services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: twin-ai-api
    ports:
      - "8080:8080"
    env_file:
      - .env
    environment:
      - PORT=8080
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL}
      - OLLAMA_INSTRUCT_MODEL=${OLLAMA_INSTRUCT_MODEL}
    volumes:
      - ./twin_ai_webapp:/app/twin_ai_webapp
      - ./poetry.lock:/app/twin_ai_webapp/poetry.lock
      - ./pyproject.toml:/app/twin_ai_webapp/pyproject.toml
    entrypoint:
      - /start-webapp.sh
    depends_on:
      - chroma-db
    networks:
      - twinai-net

  slackbot:
    build:
      context: .
      dockerfile: Dockerfile.slackbot
    container_name: twin-ai-slackbot
    environment:
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_APP_TOKEN=${SLACK_APP_TOKEN}
    command: python bot.py
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - twinai-net

  chroma-db:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chroma-db
    ports:
      - "8001:8000"
    volumes:
      - index_data:/chroma/.chroma/index
    networks:
      - twinai-net

  # ollama:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.ollama
  #   container_name: ollama
  #   ports:
  #     - "11435:11435"
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0:11435
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - twinai-net
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11435"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 120s

volumes:
  index_data:
    driver: local
  # ollama_data:
  #   driver: local

networks:
  twinai-net:
    driver: bridge
